# RAG Microservice

A production-ready, multi-tenant RAG (Retrieval Augmented Generation) microservice that ingests documents/videos, creates metadata-tagged embeddings, and answers course-specific queries with strict context-only responses.

## Features

- **ğŸ“„ Multi-format Ingestion**: PDF, DOCX, TXT, and video files
- **ğŸ·ï¸ Multi-tenant**: Course/module level isolation with metadata filtering
- **ğŸš« No Hallucination**: Strict context-only answers with source citations
- **âš¡ Fast Search**: Qdrant vector DB with HNSW indexing
- **ğŸ“Š Observable**: Latency and token usage metrics in responses
- **ğŸ”’ Secure**: Non-root containers, managed identity support
- **ğŸ”„ CI/CD**: GitHub Actions with linting, testing, and Azure deployment done.

## Quick Start

### 1. Install Dependencies

```bash
# Using uv (recommended)
uv pip install -r requirements.txt

# Or using pip
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env with your credentials:
# - QDRANT_URL and QDRANT_API_KEY
# - GOOGLE_API_KEY
```

### 3. Run Locally

```bash
uvicorn app.main:app --reload
```

### 4. Access API

- **Swagger UI**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

## API Endpoints

### Ingest Document

```bash
curl -X POST "http://localhost:8000/ingest" \
  -F "course_id=DL101" \
  -F "module_id=M03" \
  -F "source_type=pdf" \
  -F "file=@lecture_notes.pdf"
```

**Response:**
```json
{
  "job_id": "uuid",
  "status": "completed",
  "message": "Successfully ingested lecture_notes.pdf",
  "chunks_count": 42
}
```

### Query

```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain attention mechanism",
    "course_id": "DL101",
    "module_id": "M03",
    "top_k": 5
  }'
```

**Response:**
```json
{
  "answer": "According to the course materials [Source 1]...",
  "sources": [
    {
      "chunk_id": "uuid",
      "score": 0.92,
      "source_uri": "blob://DL101/M03/lecture.pdf#page=5",
      "source_type": "pdf",
      "text_preview": "The attention mechanism allows..."
    }
  ],
  "debug": {
    "search_latency_ms": 45,
    "llm_latency_ms": 320,
    "total_latency_ms": 380,
    "chunks_retrieved": 5
  }
}
```

## Project Structure

```
rag-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # FastAPI application
â”‚   â”œâ”€â”€ config.py        # Settings management
â”‚   â”œâ”€â”€ models.py        # Pydantic models
â”‚   â”œâ”€â”€ ingest.py        # Ingestion pipeline
â”‚   â”œâ”€â”€ query.py         # RAG query flow
â”‚   â”œâ”€â”€ embeddings.py    # Embedding generation
â”‚   â”œâ”€â”€ vectordb.py      # Qdrant client
â”‚   â”œâ”€â”€ extractors.py    # Document extraction
â”‚   â”œâ”€â”€ chunking.py      # Text chunking
â”‚   â””â”€â”€ prompts.py       # LLM prompts
â”œâ”€â”€ tests/               # Unit & integration tests
â”œâ”€â”€ infra/               # Terraform IaC
â”œâ”€â”€ .github/workflows/   # CI/CD pipeline
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Architecture

```
User â†’ FastAPI â†’ Qdrant (Vector Search) â†’ Google Gemini (LLM)
         â†“
    Document Extraction â†’ Chunking â†’ Embeddings â†’ Qdrant Upsert
```

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=app
```

## Docker

```bash
# Build
docker build -t rag-service .

# Run
docker run -p 8000:8000 --env-file .env rag-service
```

## Deployment

See `infra/` for Terraform modules to deploy on Azure:
- Azure Container Apps
- Azure Blob Storage
- Azure Key Vault

## License

MIT
